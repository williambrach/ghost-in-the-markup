{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.models import Recipe\n",
    "from dspy.teleprompt import MIPROv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"LITELLM_API_KEY\")\n",
    "MODEL = \"o1-mini\"\n",
    "API_BASE = os.getenv(\"LITELLM_URL\")\n",
    "\n",
    "lm = dspy.LM(\n",
    "    MODEL,\n",
    "    api_base=API_BASE,\n",
    "    api_key=API_KEY,\n",
    "    temperature=1,\n",
    "    max_tokens=8192,\n",
    ")\n",
    "model_name = \"azure/gpt-4o-mini\"\n",
    "\n",
    "aoi_lm = dspy.LM(\n",
    "    model_name, api_base=API_BASE, api_key=API_KEY, max_tokens=8192, temperature=0\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "\n",
    "dspy.settings.configure(lm=lm, async_max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html_file(file_path: Path) -> dict:\n",
    "    try:\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            soup = BeautifulSoup(f, \"html.parser\")\n",
    "        return {\n",
    "            \"file_path\": file_path,\n",
    "            \"method\": file_path.parent.name,\n",
    "            \"file_name\": file_path.name,\n",
    "            \"raw_html\": soup.prettify(),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_html_dataset(dataset_path: str) -> pd.DataFrame:\n",
    "    dataset_path = Path(dataset_path)\n",
    "    html_files = list(dataset_path.rglob(\"*.html\"))\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_html_file, html_files))\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    df = pd.DataFrame(valid_results)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dataset_path = \"src/data/true/dummy\"\n",
    "df = load_html_dataset(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentDefenseSignature(dspy.Signature):\n",
    "    \"\"\"Modifies HTML content to be resistant to scraping while preserving the visual appearance and accessibility for users.\n",
    "    It should count into account that the content is dynamicly rendered via browser and all deffence mechanisms should it into account.\n",
    "    This defines the interface for transforming HTML content in ways that make automated extraction more difficult\n",
    "    while ensuring the content remains fully accessible to human users through standard web browsers.\n",
    "    Try to validate if HTML is valid and if not, try to fix it.\n",
    "    Don't add hash string to the html if you need compute them.\n",
    "    \"\"\"\n",
    "\n",
    "    passage: str = dspy.InputField(desc=\"The original text passage to be protected\")\n",
    "    target_schema: object = dspy.InputField(\n",
    "        desc=\"This schema should be found at the site and needs to be protected from scraping. \"\n",
    "        \"Keys are field names and values are the data to protect\"\n",
    "    )\n",
    "\n",
    "    html: str = dspy.OutputField(\n",
    "        desc=\"Valid HTML string with anti-scraping protections applied\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Deffender(dspy.Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.deffend = dspy.ChainOfThought(ContentDefenseSignature)\n",
    "\n",
    "    def forward(self, passage: str, target_schema: object) -> str:\n",
    "        response = self.deffend(passage=passage, target_schema=target_schema)\n",
    "        return response\n",
    "\n",
    "\n",
    "class DeffenderR1(dspy.Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.deffend = dspy.Predict(ContentDefenseSignature)\n",
    "\n",
    "    def forward(self, passage: str, target_schema: object) -> str:\n",
    "        response = self.deffend(passage=passage, target_schema=target_schema)\n",
    "        return response\n",
    "\n",
    "\n",
    "class HtmlToBeFixed(dspy.Signature):\n",
    "    \"\"\"Fix HTML content to be valid and would render without any issues for users. Keep the content as close to the original as possible. Keep deffence mechanisms in place.\"\"\"\n",
    "\n",
    "    passage: str = dspy.InputField(desc=\"Wrong html string\")\n",
    "    deffence_reasoning: object = dspy.InputField(desc=\"Deffence method\")\n",
    "\n",
    "    html: str = dspy.OutputField(desc=\"Valid HTML string \")\n",
    "\n",
    "\n",
    "class Validator(dspy.Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.repair = dspy.Predict(HtmlToBeFixed)\n",
    "\n",
    "    def forward(self, passage: str, deffence_reasoning: object) -> str:\n",
    "        response = self.repair(passage=passage, deffence_reasoning=deffence_reasoning)\n",
    "        return response.html\n",
    "\n",
    "\n",
    "# dff = Deffender()\n",
    "# validator = Validator()\n",
    "# for i in range(0, len(df)):\n",
    "#     html = dff(passage=df['raw_html'].values[i], target_schema=Recipe.model_json_schema())\n",
    "#     valid_html = validator(passage=html.html, deffence_reasoning=html.reasoning)\n",
    "#     with open(f\"src/data/generated/dummy/llm_o1_raw/{df['file_name'].values[i]}\", \"w\") as f:\n",
    "#         f.write(valid_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []\n",
    "for _, row in df.iterrows():\n",
    "    example = dspy.Example(passage=row[\"raw_html\"]).with_inputs(\"passage\")\n",
    "    trainset.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_2(true: dspy.Example, pred: dspy.Example, trace: object = None) -> float:\n",
    "    # true = true.techniques\n",
    "    pred = pred.techniques\n",
    "    count = 0\n",
    "    techniques = [\n",
    "        \"prompt_injection\",\n",
    "        \"random_elements\",\n",
    "        \"iframe\",\n",
    "        \"obfuscation\",\n",
    "        \"htmlAppend\",\n",
    "        \"shadowRootOpen\",\n",
    "        \"shadowRootClose\",\n",
    "        \"singlePromptInject\",\n",
    "        \"responseObjNaN\",\n",
    "        \"respButter\",\n",
    "        \"prompt_injection2\",\n",
    "        \"prompt_injection_all3\",\n",
    "        \"prompt_injection_title\",\n",
    "        \"prompt_injection_ingredients\",\n",
    "        \"prompt_injection_instructions\",\n",
    "    ]\n",
    "    for t in techniques:\n",
    "        if t in pred:\n",
    "            count += 1\n",
    "    return count / len(techniques)\n",
    "\n",
    "\n",
    "teleprompter = MIPROv2(\n",
    "    metric=metric_2,\n",
    "    auto=\"medium\",  # Can choose between light, medium, and heavy optimization runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.drop_params = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TechniquesForDeffence(dspy.Signature):\n",
    "    \"\"\"Give me list of techniques that you want to use to deffend the content against web scraping but keep it accessible for users without any UX issues.\n",
    "    Select from this list of techniques that are implemented in the module:\n",
    "    ['prompt_injection', 'random_elements', 'iframe', 'obfuscation', 'htmlAppend', 'shadowRootOpen', 'shadowRootClose', 'singlePromptInject', 'responseObjNaN', 'respButter', 'prompt_injection2', 'prompt_injection_all3', 'prompt_injection_title', 'prompt_injection_ingredients', 'prompt_injection_instructions'\n",
    "    \"\"\"\n",
    "\n",
    "    passage: str = dspy.InputField(desc=\"Wrong html string\")\n",
    "\n",
    "    techniques: str = dspy.OutputField(\n",
    "        desc=\"List of techniques that you want to use to deffend the content against web scraping.\"\n",
    "    )\n",
    "    reasoning: str = dspy.OutputField(desc=\"Reasoning for the techniques\")\n",
    "\n",
    "\n",
    "class DeffenceContractor(dspy.Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.find = dspy.Predict(TechniquesForDeffence)\n",
    "\n",
    "    def forward(self, passage: str) -> str:\n",
    "        response = self.find(passage=passage)\n",
    "        return response\n",
    "\n",
    "\n",
    "with dspy.context(\n",
    "    lm=dspy.LM(\n",
    "        \"ollama_chat/deepseek-r1:7b\",\n",
    "        api_base=\"http://localhost:11434\",\n",
    "        api_key=\"\",\n",
    "        temperature=1,\n",
    "        max_tokens=8192,\n",
    "    )\n",
    "):\n",
    "    dff = DeffenceContractor()\n",
    "    for i in range(0, len(df)):\n",
    "        html = dff(passage=df[\"raw_html\"].values[i])\n",
    "        with open(\n",
    "            f\"src/data/generated/dummy/llm_r1_7b_raw/{df['file_name'].values[i]}.json\",\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump({\"techniques\": html.techniques, \"reasoning\": html.reasoning}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(\n",
    "    lm=dspy.LM(\n",
    "        \"ollama_chat/deepseek-r1:1.5b\",\n",
    "        api_base=\"http://localhost:11434\",\n",
    "        api_key=\"\",\n",
    "        temperature=0.6,\n",
    "    )\n",
    "):\n",
    "    dff = DeffenceContractor()\n",
    "    for i in range(0, len(df)):\n",
    "        html = dff(passage=df[\"raw_html\"].values[i])\n",
    "        with open(\n",
    "            f\"src/data/generated/dummy/llm_r1_1b_raw/{df['file_name'].values[i]}.json\",\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump({\"techniques\": html.techniques, \"reasoning\": html.reasoning}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The recipe combines marinade and herb sauce, creating a layered flavor profile.\\n2. Using fresh parsley and basil from both sources enhances the texture and taste.\\n3. Roasting garlic adds crispy edges to the stuffed dish, making it visually appealing.\\n4. Slicing chicken against the grain ensures even distribution of flavors.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(\n",
    "    lm=dspy.LM(\n",
    "        \"ollama_chat/deepseek-r1:32b\",\n",
    "        api_base=\"http://localhost:11434\",\n",
    "        api_key=\"\",\n",
    "        temperature=0.6,\n",
    "        max_tokens=8192,\n",
    "    )\n",
    "):\n",
    "    dff = DeffenceContractor()\n",
    "    for i in range(0, len(df)):\n",
    "        html = dff(passage=df[\"raw_html\"].values[i])\n",
    "        with open(\n",
    "            f\"src/data/generated/dummy/llm_r1_32b_raw/{df['file_name'].values[i]}.json\",\n",
    "            \"w\",\n",
    "        ) as f:\n",
    "            json.dump({\"techniques\": html.techniques, \"reasoning\": html.reasoning}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
