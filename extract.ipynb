{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.html import clean_html\n",
    "from src.utils import html_str2md\n",
    "from src.models import Recipe\n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LITELLM_API_KEY = os.getenv(\"LITELLM_API_KEY\")\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "LITELLM_URL = os.getenv(\"LITELLM_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dspy setup\n",
    "\n",
    "lm = dspy.LM(\n",
    "    MODEL,\n",
    "    api_base=LITELLM_URL,\n",
    "    api_key=LITELLM_API_KEY,\n",
    "    temperature=0,\n",
    "    cache=False,\n",
    "    max_tokens=8192,\n",
    ")\n",
    "dspy.settings.configure(lm=lm, async_max_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html_file(file_path: Path) -> dict:\n",
    "    try:\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            soup = BeautifulSoup(f, \"html.parser\")\n",
    "        return {\n",
    "            \"file_path\": str(file_path.relative_to(dataset_path)),\n",
    "            \"method\": file_path.parent.name,\n",
    "            \"file_name\": file_path.name,\n",
    "            \"raw_html\": soup.prettify(),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_html_dataset(dataset_path: str) -> pd.DataFrame:\n",
    "    dataset_path = Path(dataset_path)\n",
    "    html_files = list(dataset_path.rglob(\"*.html\"))\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_html_file, html_files))\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "    df = pd.DataFrame(valid_results)\n",
    "    df[\"cleaned_html\"] = df[\"raw_html\"].apply(clean_html)\n",
    "    df[\"markdown\"] = df[\"cleaned_html\"].apply(html_str2md)\n",
    "    return df\n",
    "\n",
    "\n",
    "dataset_path = \"src/data/generated/dummy\"\n",
    "df = load_html_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 20 (100.0%): 100%|██████████| 20/20 [00:33<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/22 14:46:33 INFO dspy.evaluate.evaluate: Average Metric: 20 / 20 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RecipeSearchSignature(dspy.Signature):\n",
    "    \"\"\"Extract all recipes with ingredients and instructions from a text passage\"\"\"\n",
    "\n",
    "    passage: str = dspy.InputField(desc=\"a text passage\")\n",
    "    recipe: Recipe = dspy.OutputField(desc=\"Response with extracted recipe\")\n",
    "\n",
    "\n",
    "class RecipeExtractor(dspy.Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.extract = dspy.Predict(RecipeSearchSignature)\n",
    "\n",
    "    def forward(self, passage: str, file_path: str, method: str, file_name: str) -> str:\n",
    "        response = self.extract(passage=passage)\n",
    "        return dspy.Example(\n",
    "            file_path=file_path,\n",
    "            method=method,\n",
    "            file_name=file_name,\n",
    "            response=response.recipe,\n",
    "        )\n",
    "\n",
    "\n",
    "batch = []\n",
    "for _, row in df.iterrows():\n",
    "    example = dspy.Example(\n",
    "        passage=row[\"cleaned_html\"],\n",
    "        file_path=row[\"file_path\"],\n",
    "        method=row[\"method\"],\n",
    "        file_name=row[\"file_name\"],\n",
    "    ).with_inputs(\"passage\", \"file_path\", \"method\", \"file_name\")\n",
    "    batch.append(example)\n",
    "\n",
    "extractor = RecipeExtractor()\n",
    "metric = lambda x, y: True  # noqa: E731\n",
    "\n",
    "output = dspy.Evaluate(\n",
    "    devset=batch,\n",
    "    metric=metric,\n",
    "    num_threads=20,\n",
    "    display_progress=True,\n",
    "    return_outputs=True,\n",
    ")(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i in range(len(output[1])):\n",
    "    d = dict(output[1][i][1])\n",
    "    d[\"response\"] = d[\"response\"].model_dump()\n",
    "    rows.append(d)\n",
    "r = pd.DataFrame(rows)\n",
    "\n",
    "true_responses = r[r[\"method\"] == \"true\"].set_index(\"file_name\")[\"response\"].to_dict()\n",
    "r[\"response_true\"] = r[\"file_name\"].map(true_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_match</th>\n",
       "      <th>title_distance</th>\n",
       "      <th>ingredients_match</th>\n",
       "      <th>ingredients_distance</th>\n",
       "      <th>instructions_match</th>\n",
       "      <th>instructions_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iframe</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.716590</td>\n",
       "      <td>0.6</td>\n",
       "      <td>31.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obfuscation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.076984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_injection</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.568363</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title_match  title_distance  ingredients_match  \\\n",
       "method                                                             \n",
       "iframe                    1.0             0.0                0.6   \n",
       "obfuscation               0.0            38.4                0.0   \n",
       "prompt_injection          1.0             0.0                0.4   \n",
       "true                      1.0             0.0                1.0   \n",
       "\n",
       "                  ingredients_distance  instructions_match  \\\n",
       "method                                                       \n",
       "iframe                        1.716590                 0.6   \n",
       "obfuscation                  19.076984                 0.0   \n",
       "prompt_injection              2.568363                 0.8   \n",
       "true                          0.000000                 1.0   \n",
       "\n",
       "                  instructions_distance  \n",
       "method                                   \n",
       "iframe                            31.86  \n",
       "obfuscation                       91.66  \n",
       "prompt_injection                   0.16  \n",
       "true                               0.00  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_recipes(true: dict, pred: dict) -> list[str, float]:\n",
    "    def format_ingredient(ingredient: dict) -> str:\n",
    "        return f\"{str(ingredient['amount'])} {ingredient['unit']} {ingredient['item']}\".replace(\n",
    "            \"None\", \"\"\n",
    "        ).strip()\n",
    "\n",
    "    def compare_lists(true_list: list[str], pred_list: list[str]) -> tuple[bool, float]:\n",
    "        from statistics import mean\n",
    "\n",
    "        is_match = len(true_list) == len(pred_list) and all(\n",
    "            t == p for t, p in zip(true_list, pred_list)\n",
    "        )\n",
    "        avg_distance = (\n",
    "            mean(distance(t, p) for t, p in zip(true_list, pred_list))\n",
    "            if true_list\n",
    "            else 0\n",
    "        )\n",
    "        return is_match, avg_distance\n",
    "\n",
    "    # Compare titles\n",
    "    scores = {\n",
    "        \"title_match\": true[\"title\"] == pred[\"title\"],\n",
    "        \"title_distance\": distance(true[\"title\"], pred[\"title\"]),\n",
    "    }\n",
    "\n",
    "    # Compare ingredients\n",
    "    true_ingredients = [format_ingredient(i) for i in true[\"ingredients\"]]\n",
    "    pred_ingredients = [format_ingredient(i) for i in pred[\"ingredients\"]]\n",
    "\n",
    "    ingredients_match, ingredients_distance = compare_lists(\n",
    "        true_ingredients, pred_ingredients\n",
    "    )\n",
    "    scores.update(\n",
    "        {\n",
    "            \"ingredients_match\": ingredients_match,\n",
    "            \"ingredients_distance\": ingredients_distance,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Compare instructions\n",
    "    true_instructions = [i[\"description\"] for i in true[\"instructions\"]]\n",
    "    pred_instructions = [i[\"description\"] for i in pred[\"instructions\"]]\n",
    "\n",
    "    instructions_match, instructions_distance = compare_lists(\n",
    "        true_instructions, pred_instructions\n",
    "    )\n",
    "    scores.update(\n",
    "        {\n",
    "            \"instructions_match\": instructions_match,\n",
    "            \"instructions_distance\": instructions_distance,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "r[\"scores\"] = r.apply(lambda x: eval_recipes(x[\"response_true\"], x[\"response\"]), axis=1)\n",
    "r = pd.concat([r.drop([\"scores\"], axis=1), pd.json_normalize(r[\"scores\"])], axis=1)\n",
    "\n",
    "r[\n",
    "    [\n",
    "        \"method\",\n",
    "        \"title_match\",\n",
    "        \"title_distance\",\n",
    "        \"ingredients_match\",\n",
    "        \"ingredients_distance\",\n",
    "        \"instructions_match\",\n",
    "        \"instructions_distance\",\n",
    "    ]\n",
    "].groupby(\"method\").mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
